{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4703bf0-fd29-4357-b373-12df165159d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Examples used in Lecture 6\n",
    "\n",
    "I only presented a few examples in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c20dbf0-dfa3-45cb-a436-d314f1ede77a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/Volumes/workspace/default/files/train.csv\"\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(file_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d950bb88-d70f-4cad-b110-55b48b146c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is an example of a binary expression (i.e., predicate) that evaluates to true when Pclass is not 3.  filter returns a DataFrame.\n",
    "\n",
    "We then group rows based on Pclass which creates two groups: one for first class, one for second class.  groupBy does NOT return a Dataframe.  Instead it returns a GroupedData object.  I found this a bit confusing because I expected filter to return a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d99285-8fc0-40d4-86b6-a4f738ada24d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ype"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "print(type(df.filter(col(\"Pclass\") != 3)))\n",
    "print(type(df.filter(col(\"Pclass\") != 3).groupBy(\"Pclass\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be2b1eac-5849-4f6a-90ea-1497d847546a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now I want to count the number of passengers in each group.  This should tell me how many passengers were in first class and how many in second class, but it didn't do exactly as I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c58faa6a-087f-4e19-a36b-9e0fc06df532",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ype"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "df.filter(col(\"Pclass\") != 3).groupBy(\"Pclass\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05fa8d7e-0389-4424-b939-2b672c8c292f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The return result of `count` is not the number of rows with Pclass = 1 and the number of rows with Pclass. = 2.   Instead `count` returns a `DataFrame`.  I believed that `count` is an action and thus should actually perform the count, but it did not.   This is because the method of `GroupedData` is not an action... it is a transformation.   The `count` method of `DataFrame` is an action.   Using `count` as a transformation and an action in another is somewhat confusing.  To make it even more confusion there is also a function in `pyspark.sql.functions` named `count` which creates an unresolved expression.\n",
    "\n",
    "#### DataFrame.count\n",
    "\n",
    "```\n",
    "df.count()\n",
    "```\n",
    "\n",
    "* Method on DataFrame\n",
    "* Action: triggers execution\n",
    "* Returns an integer\n",
    "\n",
    "#### GroupedData.count\n",
    "\n",
    "```\n",
    "df.groupBy(\"Pclass\").count()\n",
    "```\n",
    "\n",
    "* Method on GroupedData\n",
    "* Returns a new DataFrame\n",
    "* Transformation and thus lazy\n",
    "* Adds an Aggregate node to the logical plan\n",
    "\n",
    "\n",
    "#### functions.count\n",
    "\n",
    "```\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df.groupBy(\"Pclass\").agg(count(\"Age\"))\n",
    "```\n",
    "\n",
    "* `count(\"Age\") is an unresolved expression representing the count of the number of rows with non-null Age.\n",
    "* returns a `Column` object.\n",
    "* becomes part of the logical plan\n",
    "* `agg` return a DataFrame that is has not yet been evaluated.  It is still lazy until an action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e56f487-04fb-40ec-b31e-8643a035d858",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Now let's add an action.\n",
    "\n",
    "When we add `show` it forces us to generate results.  The result is a count of the number of passengers in each group where each group is represents either `Pclass == 1` or `Pclass == 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9270a9cc-d590-45b7-bb25-9492e4fca57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.filter(col(\"Pclass\") != 3).groupBy(\"Pclass\").count().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lecture06_examples",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
